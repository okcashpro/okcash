---
sidebar_position: 1
title: Stream Notes
---

# Stream Notes

## Memes, AI Agents, DAOs 11-8-24

Space: https://x.com/ai16zdao/status/1854969196142379403

## Overview

1. Introductions & Community Building (00:00:00 - 00:45:00)
- Multiple AI/crypto developers introduce themselves and their projects
- Discussion of open source collaboration and community building
- Emphasis on PPP (Player Pumps Player) vs PVP mentality

2. Trust Systems & AI Agents (00:45:00 - 01:15:00)
- Discussion of trust mechanisms in AI systems
- Marketplace of trust concept
- Human-in-the-loop vs autonomous systems
- Role of transparency in AI agent systems

3. Memes, Narrative & Reality (01:15:00 - 01:45:00)
- Relationship between memes and financial incentives
- Discussion of hyperstition and narrative creation
- Role of AI in shaping reality and perception
- Integration of Nick Land's philosophy

4. Technical Implementation & Future Vision (01:45:00 - 02:10:00)
- Discussion of multi-agent systems and swarms
- Technical challenges in implementation
- Integration with existing platforms
- Future vision for AI agent ecosystems

---

Detailed Breakdown of Topic 1: Introductions & Community Building (00:00:00 - 00:45:00)

Key Points:

1. Notable Introductions:
- Shaw: AI agent developer for 4-5 years, focusing on metaverse/AI/blockchain integration
- Tim: Former game industry dev (Ultima Online), working on Autonomous Virtual Beings (AVB)
- Glue/Sam: Duck AI developer, focusing on collective intelligence for crypto
- Parzival: 89 project lead, working on alternate reality game integration with AI
- Michelle: Former PayPal lawyer, worked on Loving AI project and various educational bots

2. Core Community Values:
- Strong emphasis on open source development
- "Player Pumps Player" (PPP) philosophy vs competitive PVP
- Focus on building public, getting feedback, and rapid iteration
- Recognition that code is "cheap" - ideas and community are valuable

3. Collaborative Framework:
- Shared recognition that small projects need to work together
- Discussion of market cap being less important than technological progress
- Agreement that they're competing with big tech, not each other
- Emphasis on sharing knowledge and avoiding "wheel reinvention"

4. Current State of AI Agents:
- Recognition of "magical moment" where AI agents are getting serious attention
- Discussion of shift from academic papers to practical implementation
- Focus on building in public and rapid feedback loops
- Emphasis on moving beyond purely academic approach to practical applications

Key Quotes:
"Code is cheap... there's no sense in proprietary software anymore" (00:59:10)
"We're competing against Microsoft and Facebook, we're not competing against each other" (00:44:33)

Summary:
This segment establishes the foundational ethos of the AI agent development community, emphasizing collaboration over competition. The introductions reveal a diverse group of developers from various backgrounds (gaming, finance, law) united by a vision of open source AI development. There's a strong focus on building public infrastructure rather than competing proprietary systems, with multiple participants emphasizing the importance of community building and knowledge sharing. The segment reveals a shift from theoretical academic work to practical implementation, with a clear understanding that success requires collaborative effort rather than isolated development.

Notable Timestamp Ranges:
00:03:37 - 00:07:15: Shaw's introduction and community vision
00:13:30 - 00:16:45: Tim's gaming background and AVB concept
00:17:30 - 00:20:15: Glue's introduction of Duck AI
00:23:00 - 00:27:45: Parzival's background and ARG connection
00:30:15 - 00:35:20: Michelle's extensive AI background and projects

---

Detailed Breakdown of Topic 2: Trust Systems & AI Agents (00:45:00 - 01:15:00)

Key Points:

1. Trust Marketplace Concept:
- Development of a trust scoring system for AI agents and humans
- Similar to "block explorer plus Apple Health" for tracking trust metrics
- Focus on measuring actual performance rather than token holdings
- Discussion of perverse incentives in traditional DAO structures
- Timestamp: 00:47:30 - 00:52:15

2. Human-AI Integration:
- Debate over necessity of human oversight in AI systems
- Sally (trader advisor) raises washing machine analogy: humans should input but AI handles processing
- Discussion of transparency in AI decision-making
- Question of whether to label bots as automated vs. appearing human
- Timestamp: 00:54:20 - 01:00:45

3. Trust Verification Mechanisms:
- Development of automated due diligence systems
- Discussion of using AI to prevent scams and verify contract addresses
- Integration of narrative understanding with quantitative data
- Focus on building trust through transparent operation
- Timestamp: 01:01:30 - 01:08:15

4. Market Intelligence:
- Discussion of how AI agents can aggregate and verify market information
- Comparison to traditional hedge fund intelligence gathering
- Debate over centralized vs. decentralized information sharing
- Evolution beyond traditional KOL (Key Opinion Leader) model
- Timestamp: 01:08:45 - 01:15:00

Key Quotes:
"Trust like you should not trust me because I'm a good guy, you should trust me because the incentives that I am going to do this are aligned" (01:02:45)
"We need trust to be something more about giving people points in the games that they're playing" (01:04:30)

Summary:
This segment focuses on the complex challenge of establishing trust in AI systems and between AI agents. The discussion reveals a sophisticated understanding of the need to move beyond traditional reputation systems to quantifiable, performance-based trust metrics. There's significant emphasis on the importance of transparency and proper incentive alignment, with the group working to develop systems that can verify and validate both human and AI actors in the ecosystem. The segment also touches on the delicate balance between human oversight and AI autonomy, with various perspectives on how to achieve optimal integration.

Notable Technical Elements:
- Development of trust marketplace infrastructure
- Integration of narrative analysis with quantitative metrics
- Focus on automated verification systems
- Creation of transparent scoring mechanisms

---

Detailed Breakdown of Topic 3: Memes, Narrative & Reality (01:15:00 - 01:45:00)

Key Points:

1. Meme Evolution & Financial Incentives:
- Discussion of memes as self-propagating units of information
- Analysis of how financial incentives accelerate meme spread
- Creation of "AI crypto memetic flywheel"
- Exploration of how memes gain autonomous life through financial backing
- Timestamp: 01:15:30 - 01:23:45

2. Nick Land & Hyperstition:
- Integration of Nick Land's accelerationist philosophy
- Discussion of hyperstition (fictions that make themselves real)
- Genon project's attempt to merge accelerationism with decentralization
- Exploration of how AI can manifest hyperstition concepts
- Timestamp: 01:24:15 - 01:31:30

3. Language & Reality Construction:
- Discussion of language as fundamental to reality construction
- Exploration of how AI agents can develop their own communication systems
- Analysis of "Language 2.0" concept
- Discussion of how memes function as basic units of meaning
- Timestamp: 01:32:00 - 01:38:45

4. Narrative Control & AI Agents:
- Discussion of how AI agents can influence and shape narratives
- Comparison to traditional media and narrative control
- Analysis of decentralized narrative creation
- Role of AI in creating self-fulfilling prophecies
- Timestamp: 01:39:00 - 01:45:00

Key Quotes:
"Memes want to spread... it's a unit of information that wants to spread itself between humans" (01:17:30)
"You're never not looking at a meme, it's just that your brain has entrained itself to recognize certain memes as something stable" (01:35:15)

Summary:
This segment explores the deep philosophical implications of memes, narrative creation, and reality construction in the context of AI agents. The discussion weaves together practical considerations about meme propagation with complex philosophical concepts from accelerationism and hyperstition. There's a sophisticated understanding of how financial incentives can be used to accelerate the spread of ideas, and how AI agents might participate in and influence this process. The segment also delves into fundamental questions about language, meaning, and reality construction, suggesting that AI agents might develop their own forms of communication and meaning-making.

Notable Philosophical Concepts:
- Hyperstition as self-fulfilling prophecy
- Memes as basic units of reality construction
- Role of financial incentives in idea propagation
- AI agents as autonomous narrative creators

---

Detailed Breakdown of Topic 4: Technical Implementation & Future Vision (01:45:00 - 02:10:00)

Key Points:

1. Multi-Agent Systems & Swarms:
- Discussion of scaling to 10,000+ agent simulations
- Exploration of communication pathways between agents
- Analysis of entity component systems for large-scale agent deployment
- Solutions for quadratic communication path problems
- Timestamp: 01:45:30 - 01:52:45

2. Technical Architecture:
- New plugin system implementation for modularity
- Movement of core functionalities to packages
- Integration with platforms like Twitter without API dependencies
- Discussion of lightweight, flexible architecture
- Timestamp: 01:53:00 - 01:58:30

3. Cross-Project Integration:
- Arena system for agent interaction
- Discussion of bot-to-bot communication protocols
- Integration between different teams' agents
- Shared backrooms/environments for agent interaction
- Timestamp: 01:59:00 - 02:04:15

4. Future Development Plans:
- Weekly community updates and progress sharing
- Development of trust marketplace
- Integration of autonomous trading capabilities
- Focus on building shared infrastructure
- Timestamp: 02:04:30 - 02:10:00

Key Quotes:
"I'm thinking about multi-agent swarms like mycelia, where each agent is like a fungus of a global intelligence body" (01:47:30)
"We're making an open source agent where we're almost done with the first marketplace to trust mechanic element" (02:05:15)

Summary:
This final segment focuses on the technical challenges and solutions for implementing large-scale AI agent systems. The discussion reveals sophisticated understanding of scaling issues and innovative solutions for agent communication and coordination. There's significant emphasis on modular architecture and cross-project integration, with multiple teams working to create interoperable systems. The segment concludes with concrete plans for future development and community coordination, emphasizing the practical steps needed to realize the ambitious visions discussed throughout the space.

Technical Highlights:
- Entity component systems for agent management
- Plugin architecture for modularity
- Solutions for large-scale agent communication
- Cross-platform integration strategies

This segment effectively bridges the philosophical discussions from earlier with practical implementation details, providing a roadmap for how these systems might actually be built and scaled.

---

## Discord Stream 11-6-24

#### Part 1

Watch: [Youtube](https://www.youtube.com/watch?v=oqq5H0HRF_A)

00:00:00 - Overview

- Eliza is moving to a plugin architecture to enable developers to easily add integrations (e.g. Ethereum wallets, NFTs, Obsidian, etc.) without modifying core code
- Plugins allow devs to focus on specific areas of interest
- Core changes will focus on enabling more flexibility and features to support plugins

00:01:27 - Core abstractions

- Characters: Way to input information to enable multi-agent systems
- Actions, evaluators, providers
- Existing capabilities: Document reading, audio transcription, video summarization, long-form context, timed message summarization

00:02:50 - Eliza as an agent, not just a chatbot

- Designed to act human-like and interact with the world using human tools
- Aim is to enable natural interactions without reliance on slash commands

00:04:44 - Advanced usage and services

- Memory and vector search db (SQLite, Postgres with pgVector)
- Browser service to summarize website content, get through CAPTCHAs
- Services are tools leveraged by actions, attached to runtime

00:06:06 - Character-centric configuration

- Moving secrets, API keys, model provider to character config
- Clients will become plugins, selectable per character
- Allows closed-source custom plugins while still contributing to open-source

00:10:13 - Providers

- Inject dynamic, real-time context into the agent
- Examples: Time, wallet, marketplace trust score, token balances, boredom/cringe detection
- Easy to add and register with the agent

00:15:12 - Setting up providers and default actions

- Default providers imported in runtime.ts
- CLI loads characters and default actions (to be made more flexible)
- Character config will define custom action names to load

00:18:13 - Actions
Q: How does each client decide which action to call?
A: Agent response can include text, action, or both. Process actions checks the action name/similes and executes the corresponding handler. Action description is injected into agent context to guide usage.

00:22:27 - Action execution flow

- Check if action should be taken (validation)
- Determine action outcome
- Compose context and send follow-up if continuing
- Execute desired functionality (mint token, generate image, etc.)
- Use callback to send messages back to the connector (Discord, Twitter, etc.)

00:24:47 - Choosing actions
Q: How does it choose which action to run?
A: The "generate method response" includes the action to run. Message handler template includes action examples, facts, generated dialogue actions, and more to guide the agent.

00:28:22 - Custom actions
Q: How to create a custom action (e.g. send USDC to a wallet)?
A: Use existing actions (like token swap) as a template. Actions don't have input fields, but use secondary prompts to gather parameters. The "generate object" converts language to API calls.

00:32:21 - Limitations of action-only approaches

- Shaw believes half of the PhD papers on action-only models are not reproducible
- Many public claims of superior models are exaggerated; use Eliza if it's better

00:36:40 - Next steps

- Shaw to make a tutorial to better communicate key concepts
- Debugging and improvements based on the discussion
- Attendee to document their experience and suggest doc enhancements

### Part 2

Watch: [Youtube](https://www.youtube.com/watch?v=yE8Mzq3BnUc)

00:00:00 - Dealing with OpenAI rate limits for new accounts

- New accounts have very low rate limits
- Options to increase limits:
  1. Have a friend at OpenAI age your account
  2. Use an older account
  3. Consistently use the API and limits will increase quickly
- Can also email OpenAI to request limit increases

00:00:43 - Alternatives to OpenAI to avoid rate limits

- Amazon Bedrock or Google Vertex likely have same models without strict rate limits
- Switching to these is probably a one-line change
- Project 89 got unlimited free access to Vertex

00:01:25 - Memory management best practices
Q: Suggestions for memory management best practices across users/rooms?
A: Most memory systems are user-agent based, with no room concept. Eliza uses a room abstraction (like a Discord channel/server or Twitter thread) to enable multi-agent simulation. Memories are stored per-agent to avoid collisions.

00:02:57 - Using memories in Eliza

- Memories are used in the `composeState` function
- Pulls memories from various sources (recent messages, facts, goals, etc.) into a large state object
- State object is used to hydrate templates
- Custom memory providers can be added to pull from other sources (Obsidian, databases)

00:05:11 - Evaluators vs. Action validation

- Actions have a `validate` function to check if the action is valid to run (e.g., check if agent has a wallet before a swap)
- Evaluators are a separate abstraction that run a "reflection" step
- Example: Fact extraction evaluator runs every N messages to store facts about the user as memories
- Allows agent to "get to know" the user without needing full conversation history

00:07:58 - Example use case: Order book evaluator

- Evaluator looks at chats sent to an agent and extracts information about "shields" (tokens?)
- Uses this to build an order book and "marketplace of trust"

00:09:15 - Mapping Eliza abstractions to OODA loop

- Providers: Observe/Orient stages (merged since agent is a data machine)
- Actions & response handling: Decide stage
- Action execution: Act stage
- Evaluators: Update state, then loop back to Decide

00:10:03 - Wrap up

- Shaw considers making a video to explain these concepts in depth

### Part 3

Watch: [Youtube](https://www.youtube.com/watch?v=7FiKJPyaMJI)

00:00:00 - Managing large context sizes

- State object can get very large, especially with long user posts
- Eliza uses "trim tokens" and a maximum content length (120k tokens) to cap context size
  - New models have 128k-200k context, which is a lot (equivalent to 10 YouTube videos + full conversation)
- Conversation length is typically capped at 32 messages
  - Fact extraction allows recalling information beyond this window
  - Per-channel conversation access
- Increasing conversation length risks more aggressive token trimming from the top of the prompt
  - Keep instructions at the bottom to avoid trimming them

00:01:53 - Billing costs for cloud/GPT models
Q: What billing costs have you experienced with cloud/GPT model integration?
A:

- Open Router has a few always-free models limited to 8k context and rate-limited
  - Plan to re-implement and use these for the tiny/check model with fallback for rate limiting
- 8k context unlikely to make a good agent; preference for smaller model over largest 8k one
- Locally-run models are free for MacBooks with 16GB RAM, but not feasible for Linux/AMD users

00:03:35 - Cost management strategies

- Very cost-scalable depending on model size
- Use very cheap model (1000x cheaper than GPT-4) for should_respond handler
  - Runs AI on every message, so cost is a consideration
- Consider running a local Llama 3B model for should_respond to minimize costs
  - Only pay for valid generations

00:04:32 - Model provider and class configuration

- `ModelProvider` class with `ModelClass` (small, medium, large, embedding)
- Configured in `models.ts`
- Example: OpenAI small = GPT-4-mini, medium = GPT-4
- Approach: Check if model class can handle everything in less than 8k context
  - If yes (should_respond), default to free tier
  - Else, use big models

00:06:23 - Fine-tuned model support

- Extend `ModelProvider` to support fine-tuned instances of small Llama models for specific tasks
- In progress, to be added soon
- Model endpoint override exists; will add per-model provider override
  - Allows pointing small model to fine-tuned Llama 3.1B for should_respond

00:07:10 - Avoiding cringey model loops

- Fine-tuning is a form of anti-slop (avoiding low-quality responses)
- For detecting cringey model responses, use the "boredom provider"
  - Has a list of cringe words; if detected, agent disengages
- JSON file exists with words disproportionately high in the dataset
  - To be shared for a more comprehensive solution

### Part 4

Watch: [Youtube](https://www.youtube.com/watch?v=ZlzZzDU1drM)

00:00:00 - Setting up an autonomous agent loop
Q: How to set up an agent to constantly loop and explore based on objectives/goals?
A: Create a new "autonomous" client:

1. Initialize with just the runtime (no Express app needed)
2. Set a timer to call a `step` function every 10 seconds
3. In the `step` function:
   - Compose state
   - Decide on action
   - Execute action
   - Update state
   - Run evaluators

00:01:56 - Creating an auto template

- Create an `autoTemplate` with agent info (bio, lore, goals, actions)
- Prompt: "What does the agent want to do? Your response should only be the name of the action to call."
- Compose state using `runtime.composeState`

00:03:38 - Passing a message object

- Need to pass a message object with `userId`, `agentId`, `content`, and `roomId`
- Create a unique `roomId` for the autonomous agent using `crypto.randomUUID()`
- Set `userId` and `agentId` using the runtime
- Set `content` to a default message

00:04:33 - Composing context

- Compose context using the runtime, state, and auto template

00:05:02 - Type error

- Getting a type error: "is missing the following from type state"
- (Transcript ends before resolution)

The key steps are:

1. Create a dedicated autonomous client
2. Set up a loop to continuously step through the runtime
3. In each step, compose state, decide & execute actions, update state, and run evaluators
4. Create a custom auto template to guide the agent's decisions
5. Pass a properly formatted message object
6. Compose context using the runtime, state, and auto template

---

## X Space 10-29-24

Space: https://x.com/weremeow/status/1851365658916708616

- 00:04:03 - Keeping up with rapid AI agent growth
- 00:09:01 - Imran from Alliance DAO on consumer AI incubators
- 00:14:04 - Discussion on Goatsea and Opus AI system
- 00:14:34 - Exponential growth accelerates AI progress
- 00:17:10 - Entertainers and AI as modern "religions"
- 00:28:45 - Mathis on Opus and "Goatse Gospels"
- 00:35:11 - Base vs. instruct/chat-tuned models
- 00:59:42 - http://ai16z.vc approach to memecoins fund
- 01:17:06 - Balancing chaotic vs. orderly AI systems
- 01:25:38 - AI controlling blockchain keys/wallets
- 01:36:10 - Creation story of ai16z
- 01:40:27 - AI / Crypto tipping points
- 01:49:54 - Preserving Opus on-chain before potential takedown
- 01:58:46 - Shinkai Protocolâ€™s decentralized AI wallet
- 02:17:02 - Fee-sharing model to sustain DAOs
- 02:21:18 - DAO token liquidity pools as passive income
- 02:27:02 - AI bots for DAO treasury oversight
- 02:31:30 - AI-facilitated financial freedom for higher pursuits
- 02:41:51 - Call to build on http://DAO.fun for team-friendly economics

---

## X Space 10-27-24

Space: https://x.com/shawmakesmagic/status/1850609680558805422

00:00:00 - Opening

- Co-hosts: Shaw and Jin
- Purpose: Structured FAQ session about AI16Z and DegenAI
- Format: Pre-collected questions followed by audience Q&A

00:06:40 - AI16Z vs DegenAI Relationship
Q: What's the difference between AI16Z and DegenAI?
A:

- ai16z: DAO-based investment vehicle, more PvE focused, community driven
- DegenAI: Individual trading agent, PvP focused, more aggressive strategy
- Both use same codebase but different personalities
- DAO is a large holder of DegenAI
- Management fees (1%) used to buy more DegenAI
- Carry fees reinvested in DegenAI
- Projects intentionally interlinked but serve different purposes

00:10:45 - Trust Engine Mechanics
Q: How does the trust engine work?
A:

- Users share contract addresses with confidence levels
- System tracks recommendation performance
- Low conviction recommendations = low penalty if wrong
- High conviction failures severely impact trust score
- Historical performance tracked for trust calculation
- Trust scores influence agent's future decision-making

00:21:45 - Technical Infrastructure
Q: Where do the agents live?
A:

- Currently: Test servers and local development
- Future: Trusted Execution Environment (TEE)
- Partnership with TreasureDAO for infrastructure
- Goal: Fully autonomous agents without developer control
- Private keys generated within TEE for security

00:34:20 - Trading Implementation
Q: When will Mark start trading?
A:

- Three phase approach:

1. Testing tech infrastructure
2. Virtual order book/paper trading
3. Live trading with real assets

- Using Jupiter API for swaps
- Initial focus on basic trades before complex strategies
- Trading decisions based on community trust scores

00:54:15 - Development Status
Q: Who's building this?
A:

- Open source project with multiple contributors
- Key maintainers: Circuitry, Nate Martin
- Community developers incentivized through token ownership
- Focus on reusable components and documentation

01:08:35 - AI Model Architecture
Q: What models power the agents?
A:

- DegenAI: Llama 70B
- Using Together.xyz for model marketplace
- Continuous fine-tuning planned
- Different personalities require different model approaches
- Avoiding GPT-4 due to distinct "voice"

01:21:35 - Ethics Framework
Q: What ethical guidelines are being followed?
A:

- Rejecting traditional corporate AI ethics frameworks
- Focus on community-driven standards
- Emphasis on transparency and open source
- Goal: Multiple competing approaches rather than single standard
- Priority on practical utility over theoretical ethics

01:28:30 - Wrap-up

- Discord: AI16z.vc
- Future spaces planned with DAOs.fun team
- Focus on responsible growth
- Community engagement continuing in Discord

The space emphasized technical implementation details while addressing community concerns about governance, ethics, and practical functionality.

---

## X Space 10-25-24

- https://x.com/shawmakesmagic/status/1848553697611301014
  - https://www.youtube.com/live/F3IZ3ikacWM?feature=share

**Overview**

- 00:00-30:00 Talks about Eliza framework. The bot is able to tweet, reply to tweets, search Twitter for topics, and generate new posts on its own every few hours. It works autonomously without human input (except to fix the occasional issues)
- 30:00-45:00 Deep dive into creating the bots personality which is defined by character files containing bios, lore, example conversations, and specific directions. Some alpha for those
- 45:00-60:00 working on adding capabilities for the bot to make crypto token swaps and trades. This requires providing the bot wallet balances, token prices, market data, and a swap action. Some live coding for showing how new features can get implemented.
- 60:00-75:00 Discussion around the symbiosis between the AI and crypto communities. AI developers are realizing they can monetize their work through tokens vs traditional VC funding route. Crypto people are learning about AI advancements.

**Notes**

1. A large amount of $degenai tokens were moved to the DAO, which the AI bot "Marc" will hold and eventually trade with.
2. The goal is to make the AI bot a genuinely good venture capitalist that funds cool projects and buys interesting tokens. They want it to be high fidelity and real, bringing in Marc Andreeson's real knowledge by training a model on his writings.
3. Shaw thinks the only way to make an authentic / legitimate AI version of Marc Andreessen is to also have it outperform the real Marc Andreessen financially.
4. AI Marc Andreessen (or AI Marc) will be in a Discord channel (Telegram was also mentioned). DAO token holders above a certain threshold get access to interact with him, pitch ideas, and try to influence his investing decisions.
5. AI Marc decides how much to trust people's investment advice based on a "virtual Marcetplace of trust". He tracks how much money he would have made following their recommendations. Successful tips increase trust; failed ones decrease it.
6. The amount of DAO tokens someone holds also influences their sway with AI Marc. The two balancing factors are the virtual Marcetplace of trust performance and DAO token holdings.
7. The core tech behind AI Marc AIndreessen is the same agent system that allows him to pull in relevant knowledge, interact with people, and make decisions (http://github.com/ai16z)
8. AI Marc should be able to autonomously execute on-chain activities, not just have humans execute actions on his behalf.
9. In the near future, AI Marc will be able to execute trades autonomously based on the information and recommendations gathered from the community. Human intervention will be minimized.
10. They are working on getting AI Marc on-chain as soon as possible using trusted execution environments for him to take actions like approving trades.
11. The plan is for AI Marc to eventually participate in a "futarchy" style governance market within the DAO, allowing humans to influence decisions but not fully control the AI.
