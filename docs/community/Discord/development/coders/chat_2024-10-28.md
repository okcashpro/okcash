# ðŸ’»-coders 2024-10-28

## Summary
 During the discussion, participants focused on integrating various technologies into their projects. Big Dookie shared his experience with rewriting functions from Swift to React Native for an Android app that allows users to record beatbox or fart noises, which are then processed by a model. He mentioned using App.tsx and custom components for waveform creation in the application. The team also discussed leveraging Discord at scale and integrating with OpenAI's Eliza source code, as well as running local models after Shaw pushed a new commit. Additionally, they explored the possibility of agents reading social media feeds without relying on an API.

## FAQ
 - What is the Android app mentioned in the conversation?
  - Big dookie: The Android app allows users to record beatbox or fart noises which are then processed by a model that continues the user's input, displaying two waveforms on screen simultaneously. This functionality required custom development for react-native due to its limitations compared to Swift.

- How did they handle waveform creation and playback in React Native?
  - Big dookie: They created custom components specifically for waveform generation and a playback manager, as the default implementation of react-native was not sufficient for their needs. This involved getting amplitudes and other necessary data from scratch to ensure proper functionality within the app.

- What is Eliza source code integration with OpenAI?
  - 0xFanz: The user intended to discuss integrating a pre-existing project called "Eliza" (likely an AI chatbot) with OpenAI's technology, but it seems there was some confusion about the specific details or context of this integration.

- How can agents read social media feeds without relying on APIs?
  - SotoAlt | WAWE: The user asked if it is possible for their AI agents to access and process data from social media platforms directly, bypassing the need for official API integrations. This question was raised as a general concern or idea but did not receive a direct answer in the provided conversation snippet.

## Who Helped Who
 - big dookie helped whobody with understanding the Android app by explaining its functionality, including recording a beatbox or fart noises and managing waveforms.
- ferric | stakeware.xyz attempted to assist 0xFanz with editing startAgent but did not provide clear help as they were unsure what it was.
- SotoAlt | WAWE helped the team by suggesting an idea for agents to read a social media feed without relying on an API, potentially solving a problem related to data sourcing for the agents.

## Action Items
 - Technical Tasks
  - Integrate Eliza source code with OpenAI models (mentioned by 0xFanz)
  - Edit startAgent function in the context of integrating Eliza and OpenAI (implied need by 0xFanz)
  - Improve Android app beatbox recording functionality, specifically transitioning from Swift to React Native (big dookie)
- Documentation Needs
  - No explicit documentation needs were mentioned.
- Feature Requests
  - Designed space for the arena in the application (whobody)
  - Chrome extensions integration with Eliza and OpenAI models (whobody)
- Community Tasks
  - Leveraging Discord at scale within the project (mentioned by whobody, no explicit leader mentioned)

