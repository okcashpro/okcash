# OKai

<img src="./docs/static/img/okai_banner.png" alt="OKai Banner" width="100%" />

## la fonctionnalit√©

- üõ† soutenir la connexion discord/ twitter /telegram
- üë• soutien aux agents multimodaux
- üìö simple √† importer des documents et interagir avec les documents
- m√©moire et stockage des documents accessibles
- üöÄ haute scalabilit√©, vous pouvez personnaliser les clients et les comportements pour une extension fonctionnelle
- ‚òÅ Ô∏è plusieurs mod√®les, y compris Llama, OpenAI Grok Anthropic, etc.
- üì¶ simple et facile √† utiliser

Que pouvez-vous faire avec OKai?

- ü§ñ le chatbot
- üïµ Ô∏è Agents autonomes
- üìà processus m√©tier pour automatiser le traitement
- üéÆ jeux PNJ

# commencez √† utiliser

**pr√©-requis (obligatoire) :**

- [Node.js 22+](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)
- installation Nodejs
- [pnpm](https://pnpm.io/installation)
- travailler avec PNPM

### √©diter le fichier.env

- copiez.env.example en.env et remplissez la valeur appropri√©e
- modifier l‚Äôenvironnement twitter et entrer votre compte twitter et mot de passe

### modifier les fichiers de r√¥les

- voir le document `src/core/defaultCharacter ts` - vous pouvez le modifier
- vous pouvez √©galement utiliser `node --loader ts-node/esm src/index.ts --characters="path/to/your/character.json" ` et simultan√©ment plusieurs robots.

Apr√®s avoir termin√© la configuration des fichiers de compte et de r√¥le, lancez votre bot en tapant la ligne de commande suivante:

```
pnpm i
pnpm start
```

# personnalisez votre OKai

### ajouter un comportement r√©gulier

Pour √©viter les conflits Git dans le r√©pertoire core, nous vous recommandons d‚Äôajouter les actions personnalis√©es dans le r√©pertoire custom_actions et de les configurer dans le fichier okaiconfig.yaml. Vous pouvez consulter l‚Äôexemple dans le fichier okaiconfig.example.yaml.

## configurez diff√©rents grands mod√®les

### configurer Llama

Vous pouvez ex√©cuter en d√©finissant la variable d‚Äôenvironnement `XAI_MODEL` √† `meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo` ou `meta-llama/Meta-Llama-3.1-405B-Instruct` Llama 70B ou 405B mod√®le

### configurer OpenAI

Vous pouvez ex√©cuter le mod√®le OpenAI en d√©finissant la variable d‚Äôenvironnement `XAI_MODEL` √† `gpt-4o-mini` ou `gpt-4o`

## autres demandes

Vous devrez peut-√™tre installer Sharp. Si vous voyez une erreur au d√©marrage, essayez d‚Äôinstaller avec la commande suivante:

```
pnpm install --include=optional sharp
```

# param√®tres de l‚Äôenvironnement

Vous devez ajouter des variables d‚Äôenvironnement √† votre fichier.env pour vous connecter √† diff√©rentes plates-formes:

```
# Required environment variables
DISCORD_APPLICATION_ID=
DISCORD_API_TOKEN= # Bot token
OPENAI_API_KEY=sk-* # OpenAI API key, starting with sk-
ELEVENLABS_XI_API_KEY= # API key from elevenlabs

# ELEVENLABS SETTINGS
ELEVENLABS_MODEL_ID=eleven_multilingual_v2
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM
ELEVENLABS_VOICE_STABILITY=0.5
ELEVENLABS_VOICE_SIMILARITY_BOOST=0.9
ELEVENLABS_VOICE_STYLE=0.66
ELEVENLABS_VOICE_USE_SPEAKER_BOOST=false
ELEVENLABS_OPTIMIZE_STREAMING_LATENCY=4
ELEVENLABS_OUTPUT_FORMAT=pcm_16000

TWITTER_DRY_RUN=false
TWITTER_USERNAME= # Account username
TWITTER_PASSWORD= # Account password
TWITTER_EMAIL= # Account email
TWITTER_COOKIES= # Account cookies

X_SERVER_URL=
XAI_API_KEY=
XAI_MODEL=


# For asking Claude stuff
ANTHROPIC_API_KEY=

# EVM
EVM_PRIVATE_KEY=EXAMPLE_WALLET_PRIVATE_KEY

# Solana
SOLANA_PRIVATE_KEY=EXAMPLE_WALLET_PRIVATE_KEY
SOLANA_PUBLIC_KEY=EXAMPLE_WALLET_PUBLIC_KEY

# Fallback Wallet Configuration (deprecated)
WALLET_PRIVATE_KEY=EXAMPLE_WALLET_PRIVATE_KEY
WALLET_PUBLIC_KEY=EXAMPLE_WALLET_PUBLIC_KEY

BIRDEYE_API_KEY=

SOL_ADDRESS=So11111111111111111111111111111111111111112
SLIPPAGE=1
RPC_URL=https://api.mainnet-beta.solana.com
HELIUS_API_KEY=


## Telegram
TELEGRAM_BOT_TOKEN=

TOGETHER_API_KEY=
```

# param√®tres locaux

### ensemble CUDA

Si vous avez une carte graphique nvidia haute performance, vous pouvez faire l‚Äôacc√©l√©ration locale avec la ligne de commande suivante CUDA

```
pnpm install
npx --no node-llama-cpp source download --gpu cuda
```

Assurez-vous d‚Äôavoir le kit complet CUDA install√©, y compris cuDNN et cuBLAS

### ex√©cution locale

Ajoutez XAI_MODEL et d√©finissez-le √† l‚Äôune des options ci-dessus [use Llama run](#run-with-llama)
Vous pouvez laisser X_SERVER_URL et XAI_API_KEY vides, qui t√©l√©chargera le mod√®le de huggingface et le consultera localement

# le client

Pour savoir comment configurer votre bot discord, vous pouvez consulter la documentation officielle de discord

# le d√©veloppement

## le test

Ligne de commande pour plusieurs m√©thodes de test:

```bash
pnpm test           # Run tests once
pnpm test:watch    # Run tests in watch mode
```

Pour les tests sp√©cifiques √† la base de donn√©es:

```bash
pnpm test:sqlite   # Run tests with SQLite
pnpm test:sqljs    # Run tests with SQL.js
```

Les tests sont √©crits en Jest et se trouvent dans le fichier SRC /\*_/_.test.ts. L‚Äôenvironnement de test est configur√© comme suit:

- chargement des variables d‚Äôenvironnement de.env.test
- utilisez un temps d‚Äôattente de 2 minutes pour ex√©cuter des tests de longue dur√©e
- support du module ESM
- ex√©cuter les tests dans l‚Äôordre (--runInBand)

Pour cr√©er un nouveau test, ajoutez un fichier.test.ts √† c√¥t√© du code √† tester.
