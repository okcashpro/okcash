# discussion 2024-07-06

## Summary
 In the Discord chat, Shaw shared links to research on slot attention (arXiv paper) and MISCA repository, expressing intentions to experiment with slot attention for learning correct features without hand engineering in transformers. Stanley joined the server, followed by Shaw sharing a link to MimicMotion's GitHub page, discussing animated characters for text-to-video projects, and considering an ensemble of motion diffusion and MimicMotion techniques. Metapontum contributed with a YouTube video suggestion on slot attention, which Shaw planned to watch later, expressing preference for prior content involving Hodel. Jordan also joined the server as Shaw mentioned upcoming projects requiring assistance, potentially through bounties.

## FAQ
 - What is the purpose of slot attention in transformers?
  - Shaw: Slot attention allows you to learn potentially correct features without hand engineering, making models more object-centric rather than relying on statistical likelihoods of neighboring elements.

- How can one obtain animated characters for text2vid applications?
  - Shaw: Currently working with MimicMotion (https://github.com/tencent/MimicMotion) and considering ensembling motion diffusion techniques to create animated characters from textual descriptions.

## Who Helped Who
 - Shaw helped Stanley with accessing resources by providing links to GitHub repositories related to machine learning models.

- Metapontum helped Shaw with entertainment or relaxation by sharing a YouTube video recommendation, which Shaw appreciated and planned to watch later.

- Shaw offered potential assistance to Jordan (and others) by mentioning upcoming projects where he might need help and considering the use of bounties for support.

## Action Items
 Technical Tasks:
  - Experiment with slot attention in transformer models (mentioned by Shaw)
  - Ensemble motion diffusion and MimicMotion techniques (considered by Shaw)
Documentation Needs:
  
Feature Requests:
  - Develop animated characters for text-to-video applications using current gig resources (currently being worked on by Shaw)
Community Tasks:

